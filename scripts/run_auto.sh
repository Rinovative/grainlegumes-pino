#!/usr/bin/env bash
# ============================================================
# scripts/run_auto.sh â€“ Cluster-Docker + GPU-Freiheitscheck + interaktiver Startmodus
# ============================================================

SCRIPT_PATH=$1
LOG_DIR="./logs"
LOG_FILE="${LOG_DIR}/$(basename "${SCRIPT_PATH%.*}")_$(date +%Y%m%d_%H%M%S).out"

# ============================================================
# ðŸ§  1. Umgebungserkennung
# ============================================================
if [ -f "/.dockerenv" ] && command -v nvidia-smi &>/dev/null; then
    ENV="cluster_docker"
else
    ENV="local"
fi

# ============================================================
# ðŸ“Š 2. GPU-Statusanzeige
# ============================================================
show_gpu_status() {
    echo "ðŸ“Š Aktuelle GPU-Auslastung:"
    if command -v nvidia-smi &>/dev/null; then
        nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total \
                   --format=csv,noheader,nounits
    else
        echo "âš ï¸  Kein nvidia-smi verfÃ¼gbar."
    fi
    echo "------------------------------------------------------------"
}

# ============================================================
# ðŸ¤– 3. Automatische GPU-Auswahl (Default)
# ============================================================
auto_select_gpu() {
    if ! command -v nvidia-smi &>/dev/null; then
        echo 0
        return
    fi
    nvidia-smi --query-gpu=index,memory.used \
               --format=csv,noheader,nounits \
        | sort -t, -k2 -n | head -n1 | cut -d',' -f1 | xargs
}

# ============================================================
# ðŸš€ 4. GPU-VerfÃ¼gbarkeit prÃ¼fen
# ============================================================
check_gpu_free() {
    local gpu_id=$1
    local active
    active=$(nvidia-smi -i "$gpu_id" --query-compute-apps=pid --format=csv,noheader | grep -v "^$" || true)
    if [ -n "$active" ]; then
        echo "âš ï¸  GPU $gpu_id hat laufende Prozesse. Trotzdem fortfahren? [y/N]"
        read -r cont
        if [[ "$cont" != "y" && "$cont" != "Y" ]]; then
            echo "âŒ Abbruch."
            exit 1
        fi
    fi
}

# ============================================================
# ðŸ“¦ 5. Logging-Verzeichnis
# ============================================================
mkdir -p "$LOG_DIR"

# ============================================================
# ðŸƒ 6. AusfÃ¼hrungslogik
# ============================================================
if [ "$ENV" = "cluster_docker" ]; then
    echo "ðŸ§ ðŸ‹ Cluster-Container erkannt â€“ GPU-FreiheitsprÃ¼fung aktiv"
    show_gpu_status

    DEFAULT_GPU=$(auto_select_gpu)
    read -p "Welche GPU soll verwendet werden? (0â€“3, Enter fÃ¼r ${DEFAULT_GPU}): " GPU_ID
    GPU_ID=${GPU_ID:-$DEFAULT_GPU}

    check_gpu_free "$GPU_ID"
    export CUDA_VISIBLE_DEVICES=$GPU_ID

    echo ""
    read -p "Im Hintergrund starten? (Enter = Ja, n = direkt im Terminal): " RUN_MODE
    echo ""

    if [[ "$RUN_MODE" == "n" || "$RUN_MODE" == "N" ]]; then
        echo "ðŸ§© Starte interaktiv auf GPU ${GPU_ID}: ${SCRIPT_PATH}"
        echo "------------------------------------------------------------"
        python3 "${SCRIPT_PATH}"
    else
        echo "ðŸš€ Starte detached auf GPU ${GPU_ID}: ${SCRIPT_PATH}"
        echo "ðŸ“ Logs: ${LOG_FILE}"
        nohup python3 "${SCRIPT_PATH}" > "${LOG_FILE}" 2>&1 &
        echo "âœ… Training lÃ¤uft im Hintergrund (PID $!)"
        echo "ðŸ‘‰ Log live ansehen mit: tail -f ${LOG_FILE}"
    fi
else
    echo "ðŸ’» Lokaler Modus â€“ lÃ¤uft direkt"
    python3 "${SCRIPT_PATH}"
fi
